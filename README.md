# Coding 
----1.Titanic Dataset Survival Prediction Using Machine Learning
Executed a full machine learning workflow on the Titanic dataset to predict passenger survival. Conducted data cleaning, handled missing values in 'Age' and 'Embarked', and applied label encoding on categorical variables like 'Sex' and 'Embarked'. Performed feature engineering by selecting impactful features such as Pclass, Sex, Fare, and Age. Trained and evaluated a Logistic Regression model, achieving high accuracy using train-test split and performance metrics like accuracy and confusion matrix. Tools used include Python, Pandas, NumPy, Scikit-learn, and Matplotlib.

üîç Key Steps You Completed:
Data Cleaning ‚Äì Removed nulls, unnecessary columns, and cleaned up entries.

Feature Engineering ‚Äì Selected meaningful features that contribute to survival prediction.

Encoding ‚Äì Transformed categorical variables using Label Encoding.

Modeling ‚Äì Built a classification model using Logistic Regression.

Evaluation ‚Äì Assessed accuracy and visualized confusion matrix.

Tools Used ‚Äì Python, Pandas, NumPy, Scikit-learn, Matplotlib

-----2.Chat-Based Sentiment Analysis Using Machine Learning
Created a sentiment classification system to label chat messages as positive, negative, or neutral. Collected and cleaned a custom dataset, removed stopwords and special characters, and applied TF-IDF vectorization to convert text into numerical features. Trained a Logistic Regression model for multi-class classification. Evaluated model performance using accuracy, precision, and F1-score. Demonstrated practical understanding of NLP preprocessing, model building, and evaluation using Python, Scikit-learn, and Pandas.

üîç What You Have Done (Broken Down):
Dataset Preparation: Created/used a large-scale chat dataset with labeled sentiments.

Data Cleaning: Removed punctuation, stopwords, and converted text to lowercase.

Vectorization: Applied TF-IDF to convert text data into numerical format.

Model Training: Used Logistic Regression for classifying sentiments.

Evaluation: Measured accuracy, precision, recall, and F1-score to validate model performance.

Tools Used: Python, Pandas, Scikit-learn, TF-IDF, Jupyter Notebook

